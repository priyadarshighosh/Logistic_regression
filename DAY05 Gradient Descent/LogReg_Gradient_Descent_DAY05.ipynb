{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression - Gradient Descent\n",
        "---\n"
      ],
      "metadata": {
        "id": "u93QB4H8gs0F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTING DATA SCIENCE LIBRARIES"
      ],
      "metadata": {
        "id": "I2xjrloHcxJQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JF9RMWnFZYq3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORT MACHINE LEARNING LIBRARIES AND CLASSES"
      ],
      "metadata": {
        "id": "-FDeOVL3M7rU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split               #for splitting the data into test and training data\n",
        "from sklearn.compose import ColumnTransformer                       #for transforming the columns\n",
        "from sklearn.impute import SimpleImputer                             #for imputing the missing values\n",
        "from sklearn.preprocessing import OneHotEncoder                      #one hot encoding\n",
        "from sklearn.preprocessing import MinMaxScaler                        #standard scaling\n",
        "\n",
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score                 # for accuracy score\n",
        "from sklearn.model_selection import cross_val_score        # for cross validation score\n",
        "\n",
        "from sklearn.linear_model import LinearRegression           # Import the LinearRegression class\n",
        "from sklearn.metrics import mean_squared_error, r2_score    # to find out the error functions\n",
        "from sklearn.preprocessing import PolynomialFeatures , StandardScaler   # for the polunomial features\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import Ridge   # ridge Regression\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "Y208GDIXgEai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and Information about the Dataset"
      ],
      "metadata": {
        "id": "XTPRT3iy9EuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "X , y  = make_classification ( n_samples = 100 , n_features = 2 ,n_informative =1 ,n_redundant=0 ,  n_classes = 2 , n_clusters_per_class = 1 , random_state = 41 ,hypercube = False , class_sep = 20  )"
      ],
      "metadata": {
        "id": "PAXRZRNaJVKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(X[:,0] , X[:,1] , c=y, cmap = 'winter' , s=100)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J4KgP90hQUwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making our Own Logistic Regression Class using Gradient Descent"
      ],
      "metadata": {
        "id": "y-V_65m4RImF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradientdescent(X, y ):\n",
        "\n",
        "  X = np.insert(X , 0 ,1 , axis = 1)    # we inserting 1 in the place of W0\n",
        "  weights = np.ones(X.shape[1])    # initialization with the weights being 1\n",
        "  lr = 0.5\n",
        "\n",
        "  for i in range(2500):\n",
        "\n",
        "\n",
        "    y_hat = sigmoid(np.dot(X , weights))            # prediction of our model from the datset\n",
        "\n",
        "    weights = weights + lr *(np.dot((y-y_hat),X)/X.shape[0]) # Changing the weights according to the difference between the real value (yi) and  the predicted value (y_hat)\n",
        "\n",
        "  return weights[1:]  , weights[0]   # returning the values of bias and the weights of different outputs"
      ],
      "metadata": {
        "id": "z4ukLmXoRPrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "  return 1/(1+np.exp(-z))"
      ],
      "metadata": {
        "id": "IxUD7h8vSDy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coef_ ,  intercept_  = gradientdescent(X , y )"
      ],
      "metadata": {
        "id": "w4x_49qTSINJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(coef_)\n",
        "print(intercept_)"
      ],
      "metadata": {
        "id": "yTb9rW3aSO2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = -( coef_[0]/coef_[1] )\n",
        "b = - (intercept_/coef_[1] )\n",
        "\n",
        "\n",
        "x_input = np.linspace(-3 , 3, 100 )\n",
        "y_output = m * x_input + b"
      ],
      "metadata": {
        "id": "KRVMkrb-8-kP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Calling Scikit learn's Logistic Regression"
      ],
      "metadata": {
        "id": "e-EIF_pw6TOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log = LogisticRegression(penalty=None , solver = 'sag')\n",
        "log.fit(X,y)                 # CALLING THE FUNCTION KEEPING NO REGULARIZATION\n"
      ],
      "metadata": {
        "id": "JrzltSKX6aog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(log.intercept_)           # calculating the  value fo weights and intercept\n",
        "print(log.coef_)"
      ],
      "metadata": {
        "id": "VGVU76Qr7u3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m1 = -(log.coef_[0][0]/log.coef_[0][1] )             # calculating the value of slope and intercept\n",
        "c1 = - (log.intercept_/log.coef_[0][1] )"
      ],
      "metadata": {
        "id": "-hayN3XN727Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_input1 = np.linspace(-3 , 3, 100 )\n",
        "y_output1 = m1 * x_input1 + c1               # output LOGISTIC REGRESSION LINE FROM THE SCIKIT LEARN FUNCTION"
      ],
      "metadata": {
        "id": "qcmZok7j8Rni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting the Graph Comparison between Our Gradient Descent and Scikit learn's Logistic Regression Class"
      ],
      "metadata": {
        "id": "WInysl3GUAir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "plt.plot(x_input , y_output , color = 'red' , linewidth = 3)\n",
        "plt.plot(x_input1 , y_output , color='black' , linewidth=3)\n",
        "\n",
        "\n",
        "plt.scatter(X[:,0] , X[:,1] , c=y, cmap = 'winter' , s=100)\n",
        "\n",
        "plt.ylim(-3,2)\n",
        "plt"
      ],
      "metadata": {
        "id": "v-2J1zsmUYa8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}